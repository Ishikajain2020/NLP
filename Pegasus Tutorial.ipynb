{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb7dc7ddcab4c28ba180219bd90f883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0aba1f509a4b86b8658f2949f98b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f0b93cd85a41db83126c64ec9fa6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec6f08a369c427ba6e54395e368b2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/3.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5303d52b82244089a83109da5c7dc13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c311730bc194a0f99ea54f67b78a092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f68ba1a16b48278a98e2afb269db3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/259 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Legal Notice\n",
    "Ref. No……………. Dated ____, __________\n",
    "\n",
    "REGD.A.D.\n",
    "\n",
    "LEGAL NOTICE\n",
    "\n",
    "To,\n",
    "\n",
    "_____________\n",
    "\n",
    "Dear Sir,\n",
    "\n",
    "Pursuant to the instructions from and on behalf of my client ___________________, through its _____________, I do hereby serve you with the following Legal Notice: -\n",
    "\n",
    "1- That my client is a ___________ firm/individual under the name and style of M/s ______________________.\n",
    "\n",
    "2- That my client is engaged in the business of __________ of the ___ etc.\n",
    "\n",
    "3- That against your valid and confirmed order my client did your job work from time to time on credit basis as you have running credit account in the account books of my client operated in due course of business.\n",
    "\n",
    "4- That my client-raised bills of each and every work performed for payment, although you have acknowledged the receipt of such bills raised by my client.\n",
    "\n",
    "5- That inspite of acknowledging the liability of payment of principal balance of Rs. _________/- you have been miserably failed to make payment of the said amount due to my client from you deliberately with malafide intent, hence you are liable to pay the said principal balance amount of Rs. __________/- alongwith interest @ __% p.a. from the date of due till actual realization of the said sum as is generally and customarily prevailing in the trade usages, which comes to Rs. __________/-\n",
    "\n",
    "6- That thus you are liable to pay the total amount of Rs. ________/- to my above named client and my above named client is entitled to recover the same from you.\n",
    "\n",
    "7- That my client requested you several times through telephonic message and by sending personal messenger to your office for release of the said outstanding payment, but you have always been dilly delaying the same on one pretext or the other and so far have not paid even a single paisa out of the said outstanding undisputed amount.\n",
    "\n",
    "I, therefore, through this Notice finally call upon you to pay to my client Rs. __________/-. along with future interest @ __ % p.a. from the date of notice till actual realization of the said amount, together with notice fee of Rs. ____/- to my client either in cash or by demand draft or Cheque which ever mode suits you better, within clear 30 days from the date of receipt of this notice, failing which my client has given me clear instructions to file civil as well as criminal lawsuit for recovery and other Miscellaneous proceedings against you in the competent court of law and in that event you shall be fully responsible for the same.\n",
    "\n",
    "A copy of this Notice has been preserved in my office for record and future course of action.\n",
    "\n",
    "(____________)\n",
    "\n",
    "ADVOCATE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 6797, 10000, 29898,   107,   566, 25620,  5613,   252, 52723,   108,\n",
       "           110, 56584, 40833,   470,   107,   251,   107,   470,   107, 64036,\n",
       "         45048,   413,   108, 88808,   940, 16930,  6381,   108,   881, 53884,\n",
       "           112,   109,  2621,   135,   111,   124,  3688,   113,   161,  1175,\n",
       "         52449, 48361,   108,   224,   203, 88808,   940,   108,   125,   171,\n",
       "         18310,  1278,   119,   122,   109,   645,  6797, 10000,   151,   233,\n",
       "          8339,   485,   161,  1175,   117,   114,   110, 56584,   940,  1419,\n",
       "           191, 38946,   365,   109,   442,   111,   669,   113,   627,   191,\n",
       "           116, 63440, 48361,   107,  5752,   485,   161,  1175,   117,  3657,\n",
       "           115,   109,   260,   113,   110, 56584,   113,   109, 52449,   733,\n",
       "           107,  4601,   485,   464,   128,  3538,   111,  3542,   385,   161,\n",
       "          1175,   368,   128,   494,   201,   135,   166,   112,   166,   124,\n",
       "           910,  1444,   130,   119,   133,   850,   910,   728,   115,   109,\n",
       "           728,  1031,   113,   161,  1175,  4279,   115,   640,   422,   113,\n",
       "           260,   107,  6220,   485,   161,  1175,   121, 37624,  4074,   113,\n",
       "           276,   111,   290,   201,  2303,   118,  1474,   108,  1670,   119,\n",
       "           133,  9652,   109,  7134,   113,   253,  4074,  2244,   141,   161,\n",
       "          1175,   107,  6604,   485,   115, 75853,   113, 21832,   109,  4132,\n",
       "           113,  1474,   113,  5191,  1716,   113,  4381,   107, 78247,   191,\n",
       "           121,   119,   133,   174, 51561,  3004,   112,   193,  1474,   113,\n",
       "           109,   243,   713,   640,   112,   161,  1175,   135,   119, 14981,\n",
       "           122, 43860,  5138,  2534,  6596,   108,  6255,   119,   127,  7917,\n",
       "           112,   626,   109,   243,  5191,  1716,   713,   113,  4381,   107,\n",
       "           110, 56584,   191,   121,   466,  3030,   820,  2650, 38925,  6835,\n",
       "           891,   107,   304,   107,   135,   109,   796,   113,   640,  3978,\n",
       "          1916, 13783,   113,   109,   243,  5906,   130,   117,  1813,   111,\n",
       "         84383, 19552,   115,   109,  1456,  3616,   116,   108,   162,   472,\n",
       "           112,  4381,   107,   110, 56584,   191,   121,  9143,   485,  2297,\n",
       "           119,   127,  7917,   112,   626,   109,   916,   713,   113,  4381,\n",
       "           107, 48944,   940,   191,   121,   112,   161,   607,  1729,  1175,\n",
       "           111,   161,   607,  1729,  1175,   117,  4746,   112,  5097,   109,\n",
       "           310,   135,   119,   107, 12393,   485,   161,  1175,  4283,   119,\n",
       "           500,   488,   224, 89720,  1285,   111,   141,  3586,   510, 20808,\n",
       "           112,   128,   629,   118,  1131,   113,   109,   243,  2796,  1474,\n",
       "           108,   155,   119,   133,   329,   174, 32566,   415, 31608,   109,\n",
       "           310,   124,   156, 58455,   132,   109,   176,   111,   167,   571,\n",
       "           133,   146,  1389,   254,   114,   612, 12955, 18240,   165,   113,\n",
       "           109,   243,  2796, 47267,   713,   107,   125,   108,  1923,   108,\n",
       "           224,   136, 10000,  1477,   443,  1071,   119,   112,   626,   112,\n",
       "           161,  1175,  4381,   107,   110, 56584,   191,   121,   107,   466,\n",
       "           122,   533,   820,  2650, 38925,  7308,   891,   107,   304,   107,\n",
       "           135,   109,   796,   113,  1748,  3978,  1916, 13783,   113,   109,\n",
       "           243,   713,   108,   424,   122,  1748,  1805,   113,  4381,   107,\n",
       "         52723,   191,   121,   112,   161,  1175,   707,   115,  1325,   132,\n",
       "           141,  1806,  4582,   132, 56393,   162,   521,  2531,  5641,   119,\n",
       "           340,   108,   373,   786,   677,   390,   135,   109,   796,   113,\n",
       "          7134,   113,   136,  1748,   108,  7315,   162,   161,  1175,   148,\n",
       "           634,   213,   786,  2621,   112,   851,  3541,   130,   210,   130,\n",
       "          3416,  6995,   118,  2597,   111,   176, 64606,  8534,   464,   119,\n",
       "           115,   109,  8897,  1462,   113,   775,   111,   115,   120,   455,\n",
       "           119,  1698,   129,  1069,  1470,   118,   109,   310,   107,   202,\n",
       "          1809,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Output summary tokens\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>Here is the copy of the legal notice sent to you by the lawyer of my client.</s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
